<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="description" content="Kai Wu's website">
    <title>Kai Wu’s Website</title>
    <style>
        /* styles.css */

        body {
            font-family: Arial, sans-serif;
            line-height: 1.6;
            background-color: #f0f0f0;
        }

        main {
            padding: 1rem;
            max-width: 800px;
            margin: 2rem auto;
            background-color: #fff;
            box-shadow: 0 0 10px rgba(0, 0, 0, 0.1);
        }

        h1, h2 {
            color: #333;
        }

        section {
            margin-bottom: 2rem;
            padding: 1rem;
        }

        footer {
            background-color: #f0f0f0;
            color: #333;
            text-align: center;
            padding: 1rem;
            margin-top: 2rem;
        }

        .links {
            display: flex;
            justify-content: center;
            gap: 1rem;
            margin-top: 1rem;
        }

        .links img {
            width: 32px;
            height: 32px;
        }
    </style>
    <script>
        // main.js

        // You can add any JavaScript functionality here, such as smooth scrolling, a responsive menu, etc.
    </script>
</head>

<body>
    <main>
        <section id="about-me">
            <h1>Kai Wu (Kyle)</h1>
            <img src="images/kaiwu_new.jpg" height="170px">
            <p>I am a principal engineer at Microsoft, working on large-scale LLM inference system optimization for high performance and resource elasticity. Before Microsoft, I was a researcher at ByteDance Infrastructure System Lab, focusing on hardware acceleration for infrastructure systems. I received my Ph.D. in Electrical Engineering and Computer Sciences from the University of California, Merced, working with Prof. Dong Li to build system supports for big, heterogeneous memory platforms. I also did internships at Lawrence Livermore National Laboratory, Los Alamos National Laboratory, and ByteDance.</p>
            <p>My interests include: 1) system optimization for high performance computing, machine learning and database workloads; 2) software/hardware co-design for data center infrastructure systems.</p>
          <!--  <p>I am a senior engineer at Microsoft. Previously (2021-2022), I was a researcher at ByteDance (TikTok) Infrastructure System Lab. Before that, I received my Ph.D. in Electrical Engineering and Computer Sciences from University of California Merced, working with <a href="http://faculty.ucmerced.edu/dong-li">Prof. Dong Li</a> on building efficient and scalable system supports for heterogeneous memory-based platforms. My research interests mainly focus on high performance computing (HPC), AI systems, runtimes, and programming models.</p>-->
            <a href="https://scholar.google.com/citations?user=p_mY8S0AAAAJ&hl=en" target="_blank">
                Google Scholar
            </a> &nbsp;&nbsp;
            <a href="https://www.linkedin.com/in/kylekaiwu" target="_blank">
                LinkedIn
            </a>
        </section>
        <section id="selected-publications">
            <h2>Selected Publications</h2>
            <ul>
                <li><b>[ICDE’23]</b> Jason Sun, Haoxiang Ma, Li Zhang, Huicong Liu, Haiyang Shi, Shangyu Luo, <u>Kai Wu</u>, Kevin Bruhwiler, Cheng Zhu, Yuanyuan Nie, Jianjun Chen, Lei Zhang and Yuming Liang. “Accelerating Cloud-Native Databases with Distributed PMem Stores”. In 39th IEEE International Conference on Data Engineering, 2023.</li>
                <li><b>[VLDB’22]</b> Jianjun Chen, Yonghua Ding, Ye Liu, Fangshi Li, Li Zhang, Mingyi Zhang, Kui Wei, Lixun Cao, Dan Zou, Yang Liu, Lei Zhang, Rui Shi, Wei Ding, <u>Kai Wu</u>, Shangyu Luo, Jason Yang Sun and Yuming Liang. “ByteHTAP: ByteDance’s HTAP System with High Data Freshness and Strong Data Consistency”. In 48th International Conference on Very Large Data Bases, 2022.</li>
                <li><b>[FAST'21]</b> <u>Kai Wu</u>, Jie Ren, Ivy Peng and Dong Li. “ArchTM: Architecture-Aware, High Performance Transaction for Persistent Memory”. In 19th USENIX Conference on File and Storage Technologies, 2021.</li>
                <li><b>[HPCA’21]</b> Jie Ren, Jiaolin Luo, <u>Kai Wu</u>, Minjia Zhang, Hyeran Jeon and Dong Li. “Efficient Tensor Migration and Allocation on Heterogeneous Memory Systems for Deep Learning”. In The 27th IEEE International Symposium on High-Performance Computer Architecture, 2021.</li>
                <li><b>[ICS’21]</b> Jie Ren, Jiaolin Luo, Ivy Peng, <u>Kai Wu</u> and Dong Li. “Optimizing Large-Scale Plasma Simulations on Persistent Memory-based Heterogeneous Memory with Effective Data Placement Across Memory Hierarchy”. In 35th International Conference on Supercomputing, 2021.</li>
                <li><b>[PACT’20]</b> <u>Kai Wu</u>, Ivy B. Peng, Jie Ren and Dong Li. “Ribbon: High Performance Cache Line Flushing for Persistent Memory”. In 29th International Conference on Parallel Architectures and Compilation Techniques, 2020.</li>
                <li><b>[IPDPS’20]</b> Ivy B. Peng, <u>Kai Wu</u>, Jie Ren, Dong Li and Maya Gokhale. “Demystifying the Performance of HPC Scientific Applications on NVM-based Memory Systems”. In 34rd IEEE International Parallel and Distributed Processing Symposium, 2020.</li>
                <li><b>[MCHPC’19]</b> Ivy B. Peng, Marty McFadden, Eric Green, Keita Iwabuchi, <u>Kai Wu</u>, Dong Li, Roger Pearce, and Maya Gokhale. “UMap: Enabling Application-driven Optimizations for Page Management”. In Workshop on Memory Centric High Performance Computing, 2019.</li>
                <li><b>[SC’18]</b> <u>Kai Wu</u>, Jie Ren and Dong Li. “Runtime Data Management on Non-Volatile Memory-based Heterogeneous Memory for Task-Parallel Programs”. In 30th ACM/IEEE International Conference for High Performance Computing, Networking, Storage and Analysis, 2018.</li>
                <li><b>[ICPP’18]</b> <u>Kai Wu</u>, Wenqian Dong, Qiang Guan, Nathan Debardeleben and Dong Li. “Modeling Application Resilience in Large Scale Parallel Execution”. In 47th International Conference on Parallel Processing, 2018.</li>
                <li><b>[SC’17]</b> <u>Kai Wu</u>, Yingchao Huang and Dong Li. “Unimem: Runtime Data Management in Non-Volatile Memory-based Heterogeneous Main Memory”. In 29th ACM/IEEE International Conference for High Performance Computing, Networking, Storage and Analysis, 2017.</li>
            </ul>
        </section>
        <section id="service">
            <h2>Service</h2>
            I have served as a reviewer for the following journals and conferences: 
            </br>
            <ul>
                <li>IEEE Transactions on Parallel and Distributed Systems</li>
                <li>IEEE Access</li>
                <li>Future Generation Computer Systems</li>
                <li>The Journal of Supercomputing</li>
                <li>ACM/IEEE International Conference for High Performance Computing, Networking, Storage, and Analysis (SC)</li>
                <li>IEEE International Parallel & Distributed Processing Symposium (IPDPS)</li>
                <li>International Conference on Parallel Processing (ICPP)</li>
                <li>IEEE International Conference on Cluster Computing (Cluster)</li>
                <li>IEEE International Conference on High Performance Computing and Communications (HPCC)</li>
                <li>IFIP International Conference on Network and Parallel Computing (NPC)</li>
                <li>IEEE International Conference on Networking, Architecture, and Storage (NAS)</li>
            </ul>
        </section>
    </main>
    <footer>
        <p>Designed by ChatGPT</p>
    </footer>
</body>

</html>

